{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNrcDRcP1kFfTYs8DF5rprK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sof4ZVQ2VG5K","executionInfo":{"status":"ok","timestamp":1719431432541,"user_tz":-330,"elapsed":24303,"user":{"displayName":"Pradyum Mistry","userId":"02567341957480123662"}},"outputId":"0aefccc8-75b8-4bc7-8216-518238708ef0"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-da4c93c4a775>:9: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv('CreditData.csv')\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.32      0.42      5874\n","           1       0.57      0.88      0.69     10599\n","           2       0.52      0.08      0.14      3527\n","\n","    accuracy                           0.57     20000\n","   macro avg       0.57      0.43      0.42     20000\n","weighted avg       0.57      0.57      0.51     20000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.impute import SimpleImputer\n","import pickle\n","\n","# Load data from CSV\n","df = pd.read_csv('train.csv')\n","\n","# Impute missing values if needed\n","imputer = SimpleImputer(strategy='mean')\n","numeric_columns = df.select_dtypes(include=['number']).columns\n","df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n","\n","# Convert Credit Score to numeric values\n","score_mapping = {'Good': 2, 'Standard': 1, 'Poor': 0}\n","df['Credit_Score'] = df['Credit_Score'].map(score_mapping)\n","\n","# Select relevant columns\n","selected_columns = numeric_columns.tolist() + ['Credit_Score']\n","df = df[selected_columns]\n","\n","# Split data into features and target\n","X = df.drop('Credit_Score', axis=1)\n","y = df['Credit_Score']\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the model\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Evaluate the model\n","y_pred = model.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","\n","# Save the model to a .pkl file\n","with open('credit_score_model.pkl', 'wb') as f:\n","    pickle.dump(model, f)"]}]}